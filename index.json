[{"content":"Hello\n","date":"26 March 2024","externalUrl":null,"permalink":"/","section":"","summary":"Hello","title":"","type":"page"},{"content":"","date":"26 March 2024","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","date":"26 March 2024","externalUrl":null,"permalink":"/posts/","section":"Blog","summary":"","title":"Blog","type":"posts"},{"content":" Introduction # March madness is currently around, and we at NobleDynamic wanted to take a crack at it. March Madness (MM) is a United States (US) college basketball tournament that features the best college basketball teams in the US. The format is single elimination, so over the course of several rounds, teams are eliminated, till eventually we get a champion. This tournament is not only a showcase of upcoming basketball talent, but also a fertile ground for data enthusiasts to analyze trends and predict outcomes.\nWe\u0026rsquo;ve decided to explore some of the most interesting functionalities offered by Fabric, a recent all-in-one cloud data tool launched by Microsoft, to tackle this challenge.\nThis is the first part of a series of posts about March Madness.\nIn this blog post, we\u0026rsquo;ll be going over:\nData Wrangling using the notebook built-in data wrangler Fast Exploratory Data Analysis (EDA) and Feature Engineering with the help of PySpark Tracking the performance of different Machine Learning (ML) Models using Fabric\u0026rsquo;s Experiments tool Selecting the best performing model using the ML Model functionality Predicting the winner of this year\u0026rsquo;s MM tournament Let\u0026rsquo;s get to the first step, getting and processing data to create a dataset with relevant features.\nData # Data Source # The data used was obtained from the on-going Kaggle competition. That competition can be found here.\nAmong all of the interesting data available, our focus for this case study was on the match-by-match statistics. This data was available for both the regular seasons and the MM tournaments, going all the way back to 2003. For each match, besides the date, the teams that were playing, and their scores, other relevant features were made available, such as field goals made and personal fouls by each team.\nFirst Look at the Data # After a quick data wrangling, it was found that, as expected with data from Kaggle, the quality was great. With no duplicates, missing values, or wrong data types. To do this, the data wrangler was explored, which is a tool built into Notebooks. It allows for easy analysis of loaded DataFrames. In a Notebook, after reading the files into PySpark DataFrames, in the \u0026ldquo;Data\u0026rdquo; section, the \u0026ldquo;Transform DataFrame in Data Wrangler\u0026rdquo; was selected, and from there the several DataFrames were explored. Specific DataFrames can be chosen, carrying out a careful inspection.\n(screenshot of selecting Data Wrangler in the Data Tab)\n(Notes on the Data Wrangler)\n(screenshot of checking that the data quality was good)\nIf it were the case that some DataFrames needed cleaning, those steps could also be done using the Data Wrangler, in a low-code format.\n(screenshot of possible cleaning steps)\nEDA # A short EDA followed, with the goal of getting a general idea of the data. Charts were plotted to get a sense of the distribution of the data and if there were any statistics that could be problematic due to, for example, very long tails.\n(screenshot of histograms)\nAt a quick glance, it was found that the data available from the regular season had normal distributions, suitable to use in the creation of features. Knowing the importance that good features have in creating solid predictive systems, the next sensible step was to carry out feature engineering to extract relevant information from the data.\nThe goal was to create a dataset where each sample would be a set of features for a MM game, such as both teams average field goals made for the regular season, and the target for each sample would be the difference between the score of the first team and the second team.\nFeature Engineering # The first feature that we decided to explore was win rate. How good would the win rate of the regular season be when predicting the winner of matches during the MM tournament? The \u0026ldquo;rule\u0026rdquo; here was that the team with the higher win rate would be predicted as the winner. Not only would it be interesting to explore that feature, but it would also provide a baseline score. At this point, the way to score each predictive system should be introduced. For this case study, the Brier score was used.\nThe Brier score can be described by the following formula:\nIt is the mean of the square of the difference between the predicted probability (p) and the actual outcome (o) for each sample. It helps quantify the accuracy of predictions, similar to how the Mean Squared Error works. However, this metric is especially useful for binary classification. The predicted probability will vary between 0 and 1, and the actual outcome will either be 0 or 1. Thus the Brier score will always be between 0 and 1. As we want the predicted probability to be as close to the actual outcome as possible, the lower the Brier score, the better, being 0 the perfect score, and 1 the worst.\nFor this case study, each sample of the dataset was a MM match, containing information for Team 1 and Team 2, the teams that played in that math. The actual outcome was considered 1 if Team 1 won, or 0 if Team 2 won. The prediction was then considered the probability of Team 1 winning.\nAfter calculating the win rate for each season, for each team, and using it to predict the outcome of games, it was found that this feature alone was not very good, with a Brier score of 0.35 (check). Knowing this, it strengthened our idea that complex patterns were at play, and using complex algorithms, such as Machine Learning Models, would be a good approach. We continued then, developing more features.\nWe went back to the statistics of the regular season. The assumption that the performance of a team throughout the regular season can be predictive of a team\u0026rsquo;s performance during the MM tournament is plausible. So, using all of the statistics available, such as field goals and personal fouls among 32 other, the mean of those was calculated for each team, in each season. Besides these, other features were created using similar assumptions. For example, another feature that was added was the team\u0026rsquo;s Elo at the end of the regular season, to act as an overall measure of the team\u0026rsquo;s quality.\nHaving a good set of features ready, it was time to move on to the Models and the Experiments.\nModels \u0026amp; Machine Learning Experiments # For the models, we opted for simple Neural Networks (NN). To determine which level of complexity would be best, we created three different NNs, with an increasing number of layers and hyper-parameters. The next step was running the experiments!\nFor that, we used the Experiment tool, in MS Fabric. After loading, normalising, and splitting the data, the goal was to try different hyper-parameters, for each model, to see which set of hyper-parameters would lead to the lowest Brier score for each model. Once that was done, we would be able to compare the best version of each model, and select the winner to get our final prediction for the champion of the MM tournament!\nWhat is an Experiment? # In Fabric, an Experiment allows us to group runs, where a run is an execution of a snippet of code. In this case, each run would be a training of a model, with a specific set of hyper-parameters. This set of hyper-parameters, along with the final model score, would be logged, and this information would be available for each run. Once enough runs have been completed, the final model scores can be compared, so that the best version of each model can be selected.\nCreating an Experiment in Fabric can be done via the UI or directly from a Notebook. The Experiment is essentially a wrapper for MLFlow Experiments, so if you\u0026rsquo;re familiar with that, this will be very straightforward. A great pro of using Fabric Experiment for experiments is that the setup is very simple, and we don\u0026rsquo;t have to worry about setting up the database where the experiments are stored. Furthermore, since the workspace that the Experiment tool is used in can be shared with others, others can easily collaborate, and participate in experiments, either writing code to run experiments, or analysing the results and so on.\nCreating an Experiment # An Experiment can be created using the UI or directly from the Notebook. Using the UI, simply select Experiment from the + New button, and choose a name.\n(show UI creating an Experiment)\nOnce that is done, to use that Experiment in a Notebook, this command has to be added:\nimport mlflow experiment_name = \u0026#34;[name of the experiment goes here]\u0026#34; # Set the experiment mlflow.set_experiment(experiment_name) Alternatively, an Experiment can be created from the Notebook, which requires one extra command:\nimport mlflow experiment_name = \u0026#34;[name of the experiment goes here]\u0026#34; # First create the experiment mlflow.create_experiment(name=experiment_name) # Then select it mlflow.set_experiment(experiment_name) Note that, if an Experiment with that name already exists, create_experiment will throw an error. In that case you might want to use the following code snippet, where first the existence of an Experiment with a given name is checked, and only if it doesn\u0026rsquo;t exist is it create.\nimport mlflow experiment_name = \u0026#34;[name of the experiment goes here]\u0026#34; # Check if experiment exists # if not, create it if not mlflow.get_experiment_by_name(experiment_name): mlflow.create_experiment(name=experiment_name) # Set experiment mlflow.set_experiment(\u0026#34;experiment_march_madness\u0026#34;) When we set the experiment, runs will be saved to that experiment. To signal that a code snippet is a run that ought to be saved to the experiment we can use the following code snippet in a Notebook cell:\nhyper_params = {\u0026#34;alpha\u0026#34;: 0.5, \u0026#34;beta\u0026#34;: 1.2} # Start the training job with `start_run()` with mlflow.start_run() as run: # Create model and dataset model = create_model(hyper_params) X, y = create_dataset() # Train model model.fit(X, y) # Calculate score score = lr.score(X, y) # Log metrics and hyper-parameters print(\u0026#34;Log metric.\u0026#34;) mlflow.log_metric(\u0026#34;score\u0026#34;, score) print(\u0026#34;Log params.\u0026#34;) mlflow.log_param(\u0026#34;alpha\u0026#34;, hyper_params[\u0026#34;alpha\u0026#34;]) mlflow.log_param(\u0026#34;alpha\u0026#34;, hyper_params[\u0026#34;alpha\u0026#34;]) The general workflow is described in the code snippet above. After setting the experiment and starting a run, a model is trained, and its score and hyper-parameters are logged.\nAnother very useful tool in Fabric that should be introduced now is the ML Model tool. This tool is essentially a wrapper for the MLFlow Model Registry. It allows us to register models and keep track of different versions and their respective performances. For this case study, this was perfect. Each of the three different models were registered under a different name, and each version was saved, along with its score. To do that, a couple of extra lines are needed:\nhyper_params = {\u0026#34;alpha\u0026#34;: 0.5, \u0026#34;beta\u0026#34;: 1.2} # Start the training job with `start_run()` with mlflow.start_run() as run: ... (previous code) # Log a model mlflow.tensorflow.log_model(lr, \u0026#34;my_model_1\u0026#34;) # Get model URI model_uri = f\u0026#34;runs:/{run.info.run_id}/my_model_1\u0026#34; # Select Model Name model_name = \u0026#34;Model1\u0026#34; # Register Model result = mlflow.register_model(model_uri, model_name) In this case, if a ML Model with the model_name already exists, a new version is added. If it doesn\u0026rsquo;t exist, an ML Model is created with that name and the logged model is considered the first version.\nAn ML Model can also be created via Fabric\u0026rsquo;s UI. Model versions of said ML Model can be imported from runs from several different Experiments. (Screenshot UI ML Model)\nConsidering this case study, an Experiment was created for each of the three models. Several runs were executed, testing different sets of hyper-parameters, and registering a new version of each model along the way.\nAfter that was done, the next step was selecting the best model. This could have been done visually, using the UI.\n(screenshot comparing different runs in each experiment) (comparing different ML Models)\nAlternatively, it can also be done via code, by getting all of the versions of all of the ML Models performance, and selecting the version with the best score.\nmlmodel_names = [\u0026#34;Model1\u0026#34;, \u0026#34;Model2\u0026#34;, \u0026#34;Model3\u0026#34;] best_score = 2 metric_name = \u0026#34;brier\u0026#34; best_model = {\u0026#34;model_name\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;model_version\u0026#34;: -1} for mlmodel in mlmodel_names: model_versions = client.search_model_versions(filter_string=f\u0026#34;name = \u0026#39;{mlmodel}\u0026#39;\u0026#34;) for version in model_versions: # Get metric history for Brier score and run ID metric_history = client.get_metric_history(run_id=version.run_id, key=metric_name) # If score better than best score, save model name and version if metric_history: last_value = metric_history[-1].value if last_value \u0026lt; best_score: best_model[\u0026#34;model_name\u0026#34;] = mlmodel best_model[\u0026#34;model_version\u0026#34;] = version best_score = last_value else: continue After finding the best model, using it to get the final predictions can be be done using the following code snippet:\nimport mlflow from synapse.ml.predict import MLFlowTransformer df = spark.read.format(\u0026#34;delta\u0026#34;).load( \u0026#34;Files/dataset\u0026#34; ) model = MLFlowTransformer( inputCols=[], # fill in list with names of feature columns outputCol=\u0026#34;predictions\u0026#34;, # select output column modelName=best_model[\u0026#34;model_name\u0026#34;], modelVersion=best_model[\u0026#34;model_version\u0026#34;] ) df = model.transform(df) Predicting the Winner of the MM Tournament # Now, to predict the winner of the MM tournament we had to apply the best model to all of the games in the bracket successively.\nAnd the predicted MM tournament winner is\u0026hellip;\nConclusion # (summary of the main ideas)\nStay tuned for more! ðŸ‘‹\n","date":"26 March 2024","externalUrl":null,"permalink":"/posts/march_madness_1/","section":"Blog","summary":"Introduction # March madness is currently around, and we at NobleDynamic wanted to take a crack at it.","title":"March Madness part 1","type":"posts"},{"content":"","date":"26 March 2024","externalUrl":null,"permalink":"/authors/martimchaves/","section":"Authors","summary":"","title":"Martimchaves","type":"authors"},{"content":"","date":"26 March 2024","externalUrl":null,"permalink":"/authors/rogernoble/","section":"Authors","summary":"","title":"Rogernoble","type":"authors"},{"content":" Website # The information contained in this website is for general information purposes only. The information is provided by Noble Dynamic Limited and while we endeavour to keep the information up to date and correct, we make no representations or warranties of any kind, express or implied, about the completeness, accuracy, reliability, suitability or availability with respect to the website or the information, products, services, or related graphics contained on the website for any purpose.\nAny reliance you place on such information is therefore strictly at your own risk.\nIn no event will we be liable for any loss or damage including without limitation, indirect or consequential loss or damage, or any loss or damage whatsoever arising from loss of data or profits arising out of, or in connection with, the use of this website.\nEmails # Emails and any files or attachments sent by Noble Dynamic are confidential and solely for the use of the individual or organisation to whom they are addressed.\nIf you have received and email in error, please immediately notify the sender. Any disclosure, copying or distribution of our emails, including attachments, is strictly prohibited. Any views or opinions presented do not necessarily represent those of the company.\nWarning: Computer viruses can be transmitted via email. The company takes reasonable precautions to ensure no viruses are present but accepts no liability for any loss or damage arising from the use of our emails or attachments.\n","date":"16 August 2022","externalUrl":null,"permalink":"/disclaimer/","section":"","summary":"Website # The information contained in this website is for general information purposes only.","title":"Disclaimer","type":"page"},{"content":"By using this website, you agree to comply with, and be bound by, the following terms and conditions of use, which together with our privacy policy govern Noble Dynamic Limitedâ€™s relationship with you in relation to this website. If you disagree with any part of these terms and conditions, please do not use our website.\nThe term \u0026lsquo;Noble Dynamic Limited\u0026rsquo; or \u0026lsquo;Noble Dynamic\u0026rsquo; or \u0026lsquo;us\u0026rsquo; or \u0026lsquo;we\u0026rsquo; refers to Noble Dynamic Limited incorporated and registered in England and Wales with company number 14292543 whose registered office is at: 86-90 Paul Street, London EC2A 4NE\nThe term \u0026lsquo;you\u0026rsquo; refers to the user or viewer of our website. The use of this website is subject to the following terms of use:\nThe content of the pages of this website is for your general information and use only. It is subject to change without notice.\nThis website does not use cookies to monitor browsing preferences.\nNeither we, nor any third parties, provide any warranty or guarantee as to the accuracy, timeliness, performance, completeness or suitability of the information and materials found or offered on this website for any particular purpose.\nYou acknowledge that such information and materials may contain inaccuracies or errors and we expressly exclude liability for any such inaccuracies or errors to the fullest extent permitted by law.\nYour use of any information or materials on this website is entirely at your own risk, for which we shall not be liable. It shall be your own responsibility to ensure that any products, services or information available through this website meet your specific requirements.\nThis website contains material which is owned by or licensed to us. This material includes, but is not limited to, the design, layout, look, appearance and graphics.\nReproduction is prohibited other than in accordance with the copyright notice, which forms part of these terms and conditions.\nAll trademarks reproduced in this website, which are not the property of, or licensed to, the operator, are acknowledged on the website.\nUnauthorised use of this website may give rise to a claim for damages and/or be a criminal offence.\nFrom time to time, this website may also include links to other websites. These links are provided for your convenience to provide further information. They do not signify that we endorse the website(s). We have no responsibility for the content of the linked website(s).\nThese terms and conditions are governed by the law of England and Wales. You agree to submit to the non-exclusive jurisdiction of the courts of England and Wales in relation to any disputes arising under or in connection with these terms and conditions or the contract between us.\n","date":"16 August 2022","externalUrl":null,"permalink":"/terms-conditions/","section":"","summary":"By using this website, you agree to comply with, and be bound by, the following terms and conditions of use, which together with our privacy policy govern Noble Dynamic Limitedâ€™s relationship with you in relation to this website.","title":"Terms and Conditions","type":"page"},{"content":" Your Privacy on this Website # Noble Dynamic is committed to protecting usersâ€™ privacy. This includes nobledynamic.com and associated apps (this \u0026ldquo;Site\u0026rdquo;). We offer this statement to inform Our users of how We define, gather and use (\u0026quot;Personal Information\u0026quot;). This is submitted to Us via this Site. We will take reasonable steps to protect Personal Information submitted by users. Protection in such a way as is consistent with this Privacy Statement. Also in accordance with all applicable data protection and privacy laws. The Personal Information that We collect from users may include the following: a personâ€™s full name, address, telephone number and/ or email address.\nIf you do not wish Us to process your Personal Information for the reasons and in the manner set out in this Privacy Statement, please do not use this Site or any of the services available through it.\nOur collection of personally identifiable information # We gather information on our users in two different ways:\nYou supply it in response to a request from Us. Cookie technology. We collect Personal Information voluntarily submitted by its users as part of the registration process for its services. Competition participation will require disclosing Personal Information.\nOur use of personally identifiable information # We may use Personal Information collected online in the following ways:\nto develop and improve the products, benefits and services We or carefully selected business partners offer to Our registered users and other users of the Site; to enable users to become registered users of the Site and to interact with online products and services; for Site administration and development (for example to analyse usage trends and to make improvements to the Site in accordance with such usage trends); to contact you by post and email, or by SMS, to inform you about any of Our products and services (including those of selected business partners) that We think may be of interest. We will not do this without having your prior permission. If at any time you subsequently wish to discontinue receiving post or emails about Our products and services please indicate this by responding. If you no longer wish to receive promotional communications by SMS, you will be given the option to opt out. From time to time we may also wish to contact you by telephone. In the event that we do so we shall always respect any request you make to decline such telephone marketing in the future; to contact you, where you have authorised Us to do so or to provide you with a email newsletter; and in assessing your request for goods or services for the purposes of the prevention and detection of fraud. In the event that We undergo a re-organisation, we may transfer your Personal Information. This transfer would be to the new owner of the Site if you are a registered user.\nDisclosure of personally identifiable information # We will not sell, rent or disclose your Personal Information to third parties without permission. Hence, you agree that We may without your prior permission disclose such information to other Noble Dynamic related companies. Or our suppliers, subcontractors and business partners where necessary. This in order to operate this Site and/or to provide you with services that you have requested.\nTherefore, you agree that We may without your prior permission disclose your Personal Information to other Noble Dynamic companies. And to our suppliers, subcontractors and business partners where necessary. This in order to operate this Site and/or to provide you with services that you have requested. We may transfer your Personal Information to other Noble Dynamic companies. And to our suppliers, subcontractors, business partners located outside of the European Economic Area (\u0026quot;EEA\u0026quot;). You should be aware that some of these countries might have data protection laws. These are equivalent to the Data Protection Act 1998. It regulates the use of personal data by companies and other business in the UK. However, some may not. You hereby consent to Our transferring your Personal Information to other Noble Dynamic companies. Or our suppliers, sub-contractors and business partners located outside the EEA. All of this in connection with your use of this Site.\nHence, Personal Information may also be disclosed to third party organisations. This may be done without your prior permission where there is a legal obligation on Us to do so.\nData Protection Act 1998 # We comply with the Data Protection Act of 1998 (the \u0026ldquo;Act\u0026rdquo;). Also with all other applicable UK data protection and privacy legislation.\nSecurity of Your Information # Therefore, we take the security of your Personal Information seriously. In addition, we take all reasonable precautions to prevent the loss, misuse or alteration of it. Agents, suppliers, subcontractors, business partners have access to your Personal Information. Confidentiality is required. They are not permitted to use it for any purpose. None other than to carry out the provision of services which they are providing to Us. Or otherwise as set out in this Privacy Statement.\nWe have a secure server that uses Secure Socket Layer (SSL) encryption to protect your Personal Information.\nContact Us # Finally, if you have any questions concerning Our Privacy Statement, you can contact our team by:\nEmail: info@nobledynamic.com\nAmendments to this privacy statement # In conclusion, we reserve the right to modify or update this Privacy Statement at any time. This site publishes any amendments. Privacy Statement review encouraged. After publish of an amended Privacy Statement, consent deemed by continuing to use this Site. If you do not agree to the amendments, please do not continue to use this Site.\n","date":"16 August 2022","externalUrl":null,"permalink":"/privacy-policy/","section":"","summary":"Your Privacy on this Website # Noble Dynamic is committed to protecting usersâ€™ privacy.","title":"Privacy Policy","type":"page"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"}]