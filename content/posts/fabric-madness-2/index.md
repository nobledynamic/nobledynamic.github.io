---
title: "Fabric Madness: Feature Engineering with pyspark"
summary: "In this series of posts titled Fabric Madness, we're going to be diving deep into some of the most interesting features of Microsoft Fabric, for an end-to-end demonstration of how to train and use a machine learning model."
date: 2024-03-27T11:37:43Z
draft: true
showAuthor: true
authors:
  - "martimchaves"
  - "rogernoble"
tags:
  - "Microsoft Fabric"
  - "Spark"
series: ["Fabric Madness"]
series_order: 2
---

## Introduction

Feature Engineering is crucial in the development of Machine Learning (ML) systems. It is a step in the development cycle where raw data is processed to better represent the underlying structure of the problem at hand. As the name dictates, the aim is to create, engineer, something that represents the data - features! It is both an art and a science. Even though there are specific steps that we can take to create good features, sometimes, it is only through experimentation that good results are achieved. Good features are crucial in guaranteeing a good system performance.

As datasets grow exponentially, traditional feature engineering may struggle with the size that of very large datasets. This is where PySpark can help. Together with the collaborative nature of Fabric, tt can allow for a scalable and efficient processing of massive datasets.

In this post, we'll be going over:
- How does PySpark Work?
- Basics of PySpark
- Feature Engineering in Action

## How does PySpark Work?

## Basics of PySpark

## Feature Engineering in Action
